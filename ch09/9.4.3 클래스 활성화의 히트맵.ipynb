{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = keras.utils.get_file(\n",
    "    fname=\"elephant.jpg\",\n",
    "    origin=\"https://img-datasets.s3.amazonaws.com/elephant.jpg\")\n",
    "\n",
    "def get_img_array(img_path, target_size):\n",
    "    img = keras.utils.load_img(img_path, target_size=target_size)\n",
    "    array = keras.utils.img_to_array(img)\n",
    "    array = np.expand_dims(array, axis=0)\n",
    "    array = keras.applications.xception.preprocess_input(array)\n",
    "    return array\n",
    "\n",
    "img_array = get_img_array(img_path, target_size=(299, 299))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels.h5\n",
      "91884032/91884032 [==============================] - 9s 0us/step\n"
     ]
    }
   ],
   "source": [
    "model = keras.applications.xception.Xception(weights=\"imagenet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 884ms/step\n",
      "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/imagenet_class_index.json\n",
      "35363/35363 [==============================] - 0s 0us/step\n",
      "[('n02504458', 'African_elephant', 0.86993986), ('n01871265', 'tusker', 0.07695617), ('n02504013', 'Indian_elephant', 0.023541773)]\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(img_array)\n",
    "print(keras.applications.xception.decode_predictions(preds, top=3)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 386, 1.0000001)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(preds[0]), np.argmax(preds[0]), np.sum(preds[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.engine.input_layer.InputLayer at 0x1ff7de22400>,\n",
       " <keras.layers.convolutional.conv2d.Conv2D at 0x1ff003dfb50>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x1ff00427250>,\n",
       " <keras.layers.core.activation.Activation at 0x1ff641dae50>,\n",
       " <keras.layers.convolutional.conv2d.Conv2D at 0x1ff47596fa0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x1ff475d8790>,\n",
       " <keras.layers.core.activation.Activation at 0x1ff005a7d90>,\n",
       " <keras.layers.convolutional.separable_conv2d.SeparableConv2D at 0x1ff007c4fa0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x1ff007c4b50>,\n",
       " <keras.layers.core.activation.Activation at 0x1ff007ceb50>,\n",
       " <keras.layers.convolutional.separable_conv2d.SeparableConv2D at 0x1ff007ce3a0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x1ff007ce2b0>,\n",
       " <keras.layers.convolutional.conv2d.Conv2D at 0x1ff007bf700>,\n",
       " <keras.layers.pooling.max_pooling2d.MaxPooling2D at 0x1ff007dd8b0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x1ff007bec10>,\n",
       " <keras.layers.merging.add.Add at 0x1ff007cbdf0>,\n",
       " <keras.layers.core.activation.Activation at 0x1ff007e9af0>,\n",
       " <keras.layers.convolutional.separable_conv2d.SeparableConv2D at 0x1ff007e26d0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x1ff007dda60>,\n",
       " <keras.layers.core.activation.Activation at 0x1ff007cbe20>,\n",
       " <keras.layers.convolutional.separable_conv2d.SeparableConv2D at 0x1ff003f45e0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x1ff003ef280>,\n",
       " <keras.layers.convolutional.conv2d.Conv2D at 0x1ff007e2730>,\n",
       " <keras.layers.pooling.max_pooling2d.MaxPooling2D at 0x1ff007f6f10>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x1ff007e2790>,\n",
       " <keras.layers.merging.add.Add at 0x1ff007f6340>,\n",
       " <keras.layers.core.activation.Activation at 0x1ff007f96d0>,\n",
       " <keras.layers.convolutional.separable_conv2d.SeparableConv2D at 0x1ff007ff3d0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x1ff007faa90>,\n",
       " <keras.layers.core.activation.Activation at 0x1ff0080a520>,\n",
       " <keras.layers.convolutional.separable_conv2d.SeparableConv2D at 0x1ff007ff100>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x1ff0080ab80>,\n",
       " <keras.layers.convolutional.conv2d.Conv2D at 0x1ff007f9e50>,\n",
       " <keras.layers.pooling.max_pooling2d.MaxPooling2D at 0x1ff0193c910>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x1ff007f9eb0>,\n",
       " <keras.layers.merging.add.Add at 0x1ff0193c760>,\n",
       " <keras.layers.core.activation.Activation at 0x1ff019457f0>,\n",
       " <keras.layers.convolutional.separable_conv2d.SeparableConv2D at 0x1ff0194b2b0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x1ff0194b130>,\n",
       " <keras.layers.core.activation.Activation at 0x1ff0194b3d0>,\n",
       " <keras.layers.convolutional.separable_conv2d.SeparableConv2D at 0x1ff01951e20>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x1ff0195b850>,\n",
       " <keras.layers.core.activation.Activation at 0x1ff0195bd60>,\n",
       " <keras.layers.convolutional.separable_conv2d.SeparableConv2D at 0x1ff019654c0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x1ff01969e20>,\n",
       " <keras.layers.merging.add.Add at 0x1ff019698b0>,\n",
       " <keras.layers.core.activation.Activation at 0x1ff0196fd60>,\n",
       " <keras.layers.convolutional.separable_conv2d.SeparableConv2D at 0x1ff01975be0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x1ff0196fa90>,\n",
       " <keras.layers.core.activation.Activation at 0x1ff019755e0>,\n",
       " <keras.layers.convolutional.separable_conv2d.SeparableConv2D at 0x1ff01983a60>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x1ff01983c70>,\n",
       " <keras.layers.core.activation.Activation at 0x1ff01989a30>,\n",
       " <keras.layers.convolutional.separable_conv2d.SeparableConv2D at 0x1ff0197ad00>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x1ff0197af10>,\n",
       " <keras.layers.merging.add.Add at 0x1ff01993dc0>,\n",
       " <keras.layers.core.activation.Activation at 0x1ff0199b5b0>,\n",
       " <keras.layers.convolutional.separable_conv2d.SeparableConv2D at 0x1ff0199bbe0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x1ff0199bd90>,\n",
       " <keras.layers.core.activation.Activation at 0x1ff01957610>,\n",
       " <keras.layers.convolutional.separable_conv2d.SeparableConv2D at 0x1ff01945bb0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x1ff0195bd30>,\n",
       " <keras.layers.core.activation.Activation at 0x1ff007fa040>,\n",
       " <keras.layers.convolutional.separable_conv2d.SeparableConv2D at 0x1ff007f9a00>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x1ff007f9df0>,\n",
       " <keras.layers.merging.add.Add at 0x1ff019910d0>,\n",
       " <keras.layers.core.activation.Activation at 0x1ff01991970>,\n",
       " <keras.layers.convolutional.separable_conv2d.SeparableConv2D at 0x1ff019ac310>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x1ff007f2820>,\n",
       " <keras.layers.core.activation.Activation at 0x1ff019ae6a0>,\n",
       " <keras.layers.convolutional.separable_conv2d.SeparableConv2D at 0x1ff019ac2b0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x1ff019ae8e0>,\n",
       " <keras.layers.core.activation.Activation at 0x1ff019b17c0>,\n",
       " <keras.layers.convolutional.separable_conv2d.SeparableConv2D at 0x1ff019b8340>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x1ff019b8190>,\n",
       " <keras.layers.merging.add.Add at 0x1ff019c48e0>,\n",
       " <keras.layers.core.activation.Activation at 0x1ff019c4820>,\n",
       " <keras.layers.convolutional.separable_conv2d.SeparableConv2D at 0x1ff019cba90>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x1ff019d1c40>,\n",
       " <keras.layers.core.activation.Activation at 0x1ff019cb130>,\n",
       " <keras.layers.convolutional.separable_conv2d.SeparableConv2D at 0x1ff019d5dc0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x1ff019c4ca0>,\n",
       " <keras.layers.core.activation.Activation at 0x1ff019e3a00>,\n",
       " <keras.layers.convolutional.separable_conv2d.SeparableConv2D at 0x1ff019d57f0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x1ff019d5cd0>,\n",
       " <keras.layers.merging.add.Add at 0x1ff019f0fa0>,\n",
       " <keras.layers.core.activation.Activation at 0x1ff019f8fd0>,\n",
       " <keras.layers.convolutional.separable_conv2d.SeparableConv2D at 0x1ff019ff9d0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x1ff019ff5e0>,\n",
       " <keras.layers.core.activation.Activation at 0x1ff019ff250>,\n",
       " <keras.layers.convolutional.separable_conv2d.SeparableConv2D at 0x1ff01a0c340>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x1ff01a11be0>,\n",
       " <keras.layers.core.activation.Activation at 0x1ff01a11550>,\n",
       " <keras.layers.convolutional.separable_conv2d.SeparableConv2D at 0x1ff01a188e0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x1ff01a1eb80>,\n",
       " <keras.layers.merging.add.Add at 0x1ff01a1e640>,\n",
       " <keras.layers.core.activation.Activation at 0x1ff019ff8e0>,\n",
       " <keras.layers.convolutional.separable_conv2d.SeparableConv2D at 0x1ff019d1eb0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x1ff019d1f40>,\n",
       " <keras.layers.core.activation.Activation at 0x1ff01a08070>,\n",
       " <keras.layers.convolutional.separable_conv2d.SeparableConv2D at 0x1ff00599040>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x1ff019ac3a0>,\n",
       " <keras.layers.core.activation.Activation at 0x1ff019be760>,\n",
       " <keras.layers.convolutional.separable_conv2d.SeparableConv2D at 0x1ff01969700>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x1ff01951730>,\n",
       " <keras.layers.merging.add.Add at 0x1ff01a29700>,\n",
       " <keras.layers.core.activation.Activation at 0x1ff01a2bf10>,\n",
       " <keras.layers.convolutional.separable_conv2d.SeparableConv2D at 0x1ff01a29dc0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x1ff019b8c40>,\n",
       " <keras.layers.core.activation.Activation at 0x1ff01a320a0>,\n",
       " <keras.layers.convolutional.separable_conv2d.SeparableConv2D at 0x1ff01a32dc0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x1ff01a32070>,\n",
       " <keras.layers.core.activation.Activation at 0x1ff01a38460>,\n",
       " <keras.layers.convolutional.separable_conv2d.SeparableConv2D at 0x1ff01a38ac0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x1ff01a38b50>,\n",
       " <keras.layers.merging.add.Add at 0x1ff01a449d0>,\n",
       " <keras.layers.core.activation.Activation at 0x1ff01a561f0>,\n",
       " <keras.layers.convolutional.separable_conv2d.SeparableConv2D at 0x1ff01a56f10>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x1ff01a561c0>,\n",
       " <keras.layers.core.activation.Activation at 0x1ff01a64be0>,\n",
       " <keras.layers.convolutional.separable_conv2d.SeparableConv2D at 0x1ff01a64e50>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x1ff01a3fb50>,\n",
       " <keras.layers.convolutional.conv2d.Conv2D at 0x1ff01a44220>,\n",
       " <keras.layers.pooling.max_pooling2d.MaxPooling2D at 0x1ff01a6e790>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x1ff01a44ac0>,\n",
       " <keras.layers.merging.add.Add at 0x1ff01a52250>,\n",
       " <keras.layers.convolutional.separable_conv2d.SeparableConv2D at 0x1ff01a64040>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x1ff01a29a00>,\n",
       " <keras.layers.core.activation.Activation at 0x1ff007f6be0>,\n",
       " <keras.layers.convolutional.separable_conv2d.SeparableConv2D at 0x1ff01a83a00>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x1ff01a69850>,\n",
       " <keras.layers.core.activation.Activation at 0x1ff01a89ac0>,\n",
       " <keras.layers.pooling.global_average_pooling2d.GlobalAveragePooling2D at 0x1ff01a89e20>,\n",
       " <keras.layers.core.dense.Dense at 0x1ff01a77910>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_conv_layer_name = \"block14_sepconv2_act\"\n",
    "classifier_layer_names = [\n",
    "    \"avg_pool\",\n",
    "    \"predictions\",\n",
    "]\n",
    "last_conv_layer = model.get_layer(last_conv_layer_name)\n",
    "last_conv_layer_model = keras.Model(model.inputs, last_conv_layer.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([10, 10, 2048])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_conv_layer.output.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_pool\n",
      "predictions\n"
     ]
    }
   ],
   "source": [
    "classifier_input = keras.Input(shape=last_conv_layer.output.shape[1:])\n",
    "x = classifier_input\n",
    "for layer_name in classifier_layer_names:\n",
    "    print(layer_name)\n",
    "    x = model.get_layer(layer_name)(x)\n",
    "classifier_model = keras.Model(classifier_input, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    last_conv_layer_output = last_conv_layer_model(img_array)\n",
    "    tape.watch(last_conv_layer_output)\n",
    "    preds = classifier_model(last_conv_layer_output)\n",
    "    top_pred_index = tf.argmax(preds[0])\n",
    "    top_class_channel = preds[:, top_pred_index]\n",
    "\n",
    "grads = tape.gradient(top_class_channel, last_conv_layer_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2)).numpy()\n",
    "last_conv_layer_output = last_conv_layer_output.numpy()[0]\n",
    "for i in range(pooled_grads.shape[-1]):\n",
    "    last_conv_layer_output[:, :, i] *= pooled_grads[i]\n",
    "heatmap = np.mean(last_conv_layer_output, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 480x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "heatmap = np.maximum(heatmap, 0)\n",
    "heatmap /= np.max(heatmap)\n",
    "plt.matshow(heatmap)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\G013\\AppData\\Local\\Temp\\ipykernel_12672\\780671328.py:8: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
      "  jet = cm.get_cmap(\"jet\")\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.cm as cm\n",
    "\n",
    "img = keras.utils.load_img(img_path)\n",
    "img = keras.utils.img_to_array(img)\n",
    "\n",
    "heatmap = np.uint8(255 * heatmap)\n",
    "\n",
    "jet = cm.get_cmap(\"jet\")\n",
    "jet_colors = jet(np.arange(256))[:, :3]\n",
    "jet_heatmap = jet_colors[heatmap]\n",
    "\n",
    "jet_heatmap = keras.utils.array_to_img(jet_heatmap)\n",
    "jet_heatmap = jet_heatmap.resize((img.shape[1], img.shape[0]))\n",
    "jet_heatmap = keras.utils.img_to_array(jet_heatmap)\n",
    "\n",
    "superimposed_img = jet_heatmap * 0.4 + img\n",
    "superimposed_img = keras.utils.array_to_img(superimposed_img)\n",
    "\n",
    "save_path = \"elephant_cam.jpg\"\n",
    "superimposed_img.save(save_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
