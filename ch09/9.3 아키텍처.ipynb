{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 files belonging to 2 classes.\n",
      "Found 1000 files belonging to 2 classes.\n",
      "Found 2000 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "import os, shutil, pathlib\n",
    "from tensorflow.keras.utils import image_dataset_from_directory\n",
    "\n",
    "original_dir = pathlib.Path(\"./src_data/train\")\n",
    "new_base_dir = pathlib.Path(\"cats_vs_dogs_small\")\n",
    "\n",
    "# def make_subset(subset_name, start_index, end_index):\n",
    "#     for category in (\"cat\", \"dog\"):\n",
    "#         dir = new_base_dir / subset_name / category\n",
    "#         os.makedirs(dir)\n",
    "#         fnames = [f\"{category}.{i}.jpg\" for i in range(start_index, end_index)]\n",
    "#         for fname in fnames:\n",
    "#             shutil.copyfile(src=original_dir / fname,\n",
    "#                             dst=dir / fname)\n",
    "\n",
    "# make_subset(\"train\", start_index=0, end_index=1000)\n",
    "# make_subset(\"validation\", start_index=1000, end_index=1500)\n",
    "# make_subset(\"test\", start_index=1500, end_index=2500)\n",
    "\n",
    "train_dataset = image_dataset_from_directory(\n",
    "    new_base_dir / \"train\",\n",
    "    image_size=(180, 180),\n",
    "    batch_size=32)\n",
    "validation_dataset = image_dataset_from_directory(\n",
    "    new_base_dir / \"validation\",\n",
    "    image_size=(180, 180),\n",
    "    batch_size=32)\n",
    "test_dataset = image_dataset_from_directory(\n",
    "    new_base_dir / \"test\",\n",
    "    image_size=(180, 180),\n",
    "    batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        layers.RandomFlip(\"horizontal\"),\n",
    "        layers.RandomRotation(0.1),\n",
    "        layers.RandomZoom(0.2),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(180, 180, 3))\n",
    "x = data_augmentation(inputs)\n",
    "\n",
    "x = layers.Rescaling(1./255)(x)\n",
    "x = layers.Conv2D(filters=32, kernel_size=5, use_bias=False)(x)\n",
    "\n",
    "for size in [32, 64, 128, 256, 512]:\n",
    "    residual = x\n",
    "\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "    x = layers.SeparableConv2D(size, 3, padding=\"same\", use_bias=False)(x)\n",
    "\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "    x = layers.SeparableConv2D(size, 3, padding=\"same\", use_bias=False)(x)\n",
    "\n",
    "    x = layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n",
    "\n",
    "    residual = layers.Conv2D(\n",
    "        size, 1, strides=2, padding=\"same\", use_bias=False)(residual)\n",
    "    x = layers.add([x, residual])\n",
    "\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3141"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "63/63 [==============================] - 108s 2s/step - loss: 0.7039 - accuracy: 0.5510 - val_loss: 0.7382 - val_accuracy: 0.5000\n",
      "Epoch 2/100\n",
      "63/63 [==============================] - 105s 2s/step - loss: 0.6642 - accuracy: 0.5860 - val_loss: 0.7018 - val_accuracy: 0.5000\n",
      "Epoch 3/100\n",
      "63/63 [==============================] - 104s 2s/step - loss: 0.6438 - accuracy: 0.6335 - val_loss: 0.6923 - val_accuracy: 0.5120\n",
      "Epoch 4/100\n",
      "63/63 [==============================] - 105s 2s/step - loss: 0.6195 - accuracy: 0.6525 - val_loss: 0.6978 - val_accuracy: 0.5000\n",
      "Epoch 5/100\n",
      "63/63 [==============================] - 104s 2s/step - loss: 0.6115 - accuracy: 0.6770 - val_loss: 0.7476 - val_accuracy: 0.5000\n",
      "Epoch 6/100\n",
      "63/63 [==============================] - 105s 2s/step - loss: 0.5947 - accuracy: 0.6960 - val_loss: 0.6929 - val_accuracy: 0.5230\n",
      "Epoch 7/100\n",
      "63/63 [==============================] - 105s 2s/step - loss: 0.5932 - accuracy: 0.6830 - val_loss: 0.8590 - val_accuracy: 0.5070\n",
      "Epoch 8/100\n",
      "63/63 [==============================] - 105s 2s/step - loss: 0.5674 - accuracy: 0.7185 - val_loss: 0.8747 - val_accuracy: 0.5120\n",
      "Epoch 9/100\n",
      "63/63 [==============================] - 105s 2s/step - loss: 0.5614 - accuracy: 0.7180 - val_loss: 0.7295 - val_accuracy: 0.5780\n",
      "Epoch 10/100\n",
      "63/63 [==============================] - 104s 2s/step - loss: 0.5350 - accuracy: 0.7310 - val_loss: 0.7339 - val_accuracy: 0.6370\n",
      "Epoch 11/100\n",
      "63/63 [==============================] - 104s 2s/step - loss: 0.5249 - accuracy: 0.7350 - val_loss: 0.5333 - val_accuracy: 0.7450\n",
      "Epoch 12/100\n",
      "63/63 [==============================] - 104s 2s/step - loss: 0.5012 - accuracy: 0.7585 - val_loss: 0.5964 - val_accuracy: 0.7180\n",
      "Epoch 13/100\n",
      "63/63 [==============================] - 104s 2s/step - loss: 0.4966 - accuracy: 0.7655 - val_loss: 3.4633 - val_accuracy: 0.5130\n",
      "Epoch 14/100\n",
      "63/63 [==============================] - 104s 2s/step - loss: 0.4784 - accuracy: 0.7755 - val_loss: 1.1728 - val_accuracy: 0.5320\n",
      "Epoch 15/100\n",
      "63/63 [==============================] - 104s 2s/step - loss: 0.4690 - accuracy: 0.7730 - val_loss: 0.7745 - val_accuracy: 0.6710\n",
      "Epoch 16/100\n",
      "63/63 [==============================] - 104s 2s/step - loss: 0.4526 - accuracy: 0.7895 - val_loss: 2.8177 - val_accuracy: 0.5480\n",
      "Epoch 17/100\n",
      "63/63 [==============================] - 104s 2s/step - loss: 0.4499 - accuracy: 0.7920 - val_loss: 0.5235 - val_accuracy: 0.7600\n",
      "Epoch 18/100\n",
      "63/63 [==============================] - 105s 2s/step - loss: 0.4235 - accuracy: 0.8075 - val_loss: 0.5382 - val_accuracy: 0.7440\n",
      "Epoch 19/100\n",
      "63/63 [==============================] - 104s 2s/step - loss: 0.4257 - accuracy: 0.8065 - val_loss: 0.4869 - val_accuracy: 0.7640\n",
      "Epoch 20/100\n",
      "63/63 [==============================] - 104s 2s/step - loss: 0.4179 - accuracy: 0.7960 - val_loss: 0.5712 - val_accuracy: 0.7250\n",
      "Epoch 21/100\n",
      "63/63 [==============================] - 104s 2s/step - loss: 0.4093 - accuracy: 0.8130 - val_loss: 0.6343 - val_accuracy: 0.7690\n",
      "Epoch 22/100\n",
      "63/63 [==============================] - 104s 2s/step - loss: 0.3799 - accuracy: 0.8370 - val_loss: 0.6617 - val_accuracy: 0.6820\n",
      "Epoch 23/100\n",
      "63/63 [==============================] - 104s 2s/step - loss: 0.4010 - accuracy: 0.8170 - val_loss: 0.4200 - val_accuracy: 0.8150\n",
      "Epoch 24/100\n",
      "63/63 [==============================] - 104s 2s/step - loss: 0.3913 - accuracy: 0.8270 - val_loss: 0.7991 - val_accuracy: 0.6830\n",
      "Epoch 25/100\n",
      "63/63 [==============================] - 104s 2s/step - loss: 0.3655 - accuracy: 0.8435 - val_loss: 0.5720 - val_accuracy: 0.7430\n",
      "Epoch 26/100\n",
      "63/63 [==============================] - 104s 2s/step - loss: 0.3459 - accuracy: 0.8580 - val_loss: 0.5619 - val_accuracy: 0.7290\n",
      "Epoch 27/100\n",
      "63/63 [==============================] - 104s 2s/step - loss: 0.3649 - accuracy: 0.8405 - val_loss: 0.9986 - val_accuracy: 0.6400\n",
      "Epoch 28/100\n",
      "63/63 [==============================] - 104s 2s/step - loss: 0.3167 - accuracy: 0.8720 - val_loss: 2.0943 - val_accuracy: 0.5900\n",
      "Epoch 29/100\n",
      "63/63 [==============================] - 105s 2s/step - loss: 0.3337 - accuracy: 0.8570 - val_loss: 0.4497 - val_accuracy: 0.7840\n",
      "Epoch 30/100\n",
      "63/63 [==============================] - 104s 2s/step - loss: 0.3279 - accuracy: 0.8570 - val_loss: 0.5133 - val_accuracy: 0.7740\n",
      "Epoch 31/100\n",
      "63/63 [==============================] - 104s 2s/step - loss: 0.3339 - accuracy: 0.8520 - val_loss: 0.3671 - val_accuracy: 0.8430\n",
      "Epoch 32/100\n",
      "63/63 [==============================] - 104s 2s/step - loss: 0.3144 - accuracy: 0.8640 - val_loss: 1.0761 - val_accuracy: 0.7190\n",
      "Epoch 33/100\n",
      "63/63 [==============================] - 104s 2s/step - loss: 0.2945 - accuracy: 0.8685 - val_loss: 2.5545 - val_accuracy: 0.5440\n",
      "Epoch 34/100\n",
      "63/63 [==============================] - 105s 2s/step - loss: 0.2867 - accuracy: 0.8805 - val_loss: 0.9728 - val_accuracy: 0.6810\n",
      "Epoch 35/100\n",
      "63/63 [==============================] - 104s 2s/step - loss: 0.2705 - accuracy: 0.8870 - val_loss: 0.7608 - val_accuracy: 0.6670\n",
      "Epoch 36/100\n",
      "63/63 [==============================] - 104s 2s/step - loss: 0.2847 - accuracy: 0.8815 - val_loss: 0.5141 - val_accuracy: 0.7410\n",
      "Epoch 37/100\n",
      "63/63 [==============================] - 105s 2s/step - loss: 0.2677 - accuracy: 0.8830 - val_loss: 0.4417 - val_accuracy: 0.8440\n",
      "Epoch 38/100\n",
      "63/63 [==============================] - 107s 2s/step - loss: 0.2478 - accuracy: 0.8960 - val_loss: 0.7982 - val_accuracy: 0.8020\n",
      "Epoch 39/100\n",
      "51/63 [=======================>......] - ETA: 18s - loss: 0.2650 - accuracy: 0.8909"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"binary_crossentropy\",\n",
    "              optimizer=\"rmsprop\",\n",
    "              metrics=[\"accuracy\"])\n",
    "history = model.fit(\n",
    "    train_dataset, # image, label\n",
    "    epochs=100,\n",
    "    validation_data=validation_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "accuracy = history.history[\"accuracy\"]\n",
    "val_accuracy = history.history[\"val_accuracy\"]\n",
    "loss = history.history[\"loss\"]\n",
    "val_loss = history.history[\"val_loss\"]\n",
    "epochs = range(1, len(accuracy) + 1)\n",
    "plt.plot(epochs, accuracy, \"bo\", label=\"Training accuracy\")\n",
    "plt.plot(epochs, val_accuracy, \"b\", label=\"Validation accuracy\")\n",
    "plt.title(\"Training and validation accuracy\")\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, \"bo\", label=\"Training loss\")\n",
    "plt.plot(epochs, val_loss, \"b\", label=\"Validation loss\")\n",
    "plt.title(\"Training and validation loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
